{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "The problem we propose to address here is that of __rating prediction__. The data we have is a rating history: ratings of users for items in the interval [1,5] (1 to 5 stars rating). We can put all this data into a sparse matrix called $R$.\n",
    "\n",
    "The matrix $R$ is sparse (more than 99% of the entries are missing), and our goal is to __predict__ the missing entries. One of the solution for this rating prediction is _matrix factorization_. This is fundamentally linked to SVD, which stands for Singular Value Decomposition.\n",
    "\n",
    "Here is the matrix factorization:\n",
    "\n",
    "$R = M\\sum U^T$\n",
    "\n",
    "To be clear, SVD is an algorithm that takes the matrix $R$ as an input, and it gives you $M$, $\\sum$ and $U$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/\n",
    "2. http://www.albertauyeung.com/post/python-matrix-factorization/\n",
    "3. https://arxiv.org/pdf/1503.07475.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i, :], Q[:, j])\n",
    "                    \n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P, Q)\n",
    "        e = 0\n",
    "\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i, :], Q[:, j]), 2)\n",
    "\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta / 2) * (pow(P[i][k], 2) + pow(Q[k][j], 2))\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T\n",
    "                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.03195688  2.83201472  5.4477017   0.99689041]\n",
      " [ 3.93779077  2.21915034  4.3989906   0.99779349]\n",
      " [ 1.11553482  0.69186028  4.16784453  4.96378344]\n",
      " [ 0.94429841  0.58260453  3.38688405  3.97561872]\n",
      " [ 2.43705479  1.41955041  4.85567822  4.03535322]]\n"
     ]
    }
   ],
   "source": [
    "R = [[5,3,0,1],\n",
    "     [4,0,0,1],\n",
    "     [1,1,0,5],\n",
    "     [1,0,0,4],\n",
    "     [0,1,5,4]]\n",
    "\n",
    "R = np.array(R)\n",
    "\n",
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 2\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "P = np.random.rand(N, K)\n",
    "Q = np.random.rand(M, K)\n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "print(nR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        \"\"\"\n",
    "        Perform matrix factorization to predict empty entries in a matrix\n",
    "        \n",
    "        Arguments\n",
    "        - R (ndarray)   : user-item rating matrix\n",
    "        - K (int)       : number of latent dimension\n",
    "        - alpha (float) : learning rate\n",
    "        - beta (float)  : regularization parameter\n",
    "        \"\"\"\n",
    "        \n",
    "        self.R = R \n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        \n",
    "    def train(self):\n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "        \n",
    "        # Initialize the biases\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "        \n",
    "        # Create a list of training samples\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "        \n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print('Iterations: {}; error = {}'.format(i + 1, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        A function to compute the total mean square error\n",
    "        \"\"\"\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic gradient descent\n",
    "        \"\"\"\n",
    "        for i, j, r in self.samples:\n",
    "            # Computer prediction and error\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "            \n",
    "            # Update bias\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_u[j])\n",
    "            \n",
    "            # Update user and item latent feature matrices\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "        \n",
    "    def get_rating(self, i, j):\n",
    "        \"\"\"\n",
    "        Get the predicted rating of user i and item j\n",
    "        \"\"\"\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j,:].T)\n",
    "        return prediction\n",
    "    \n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Compute the full matrix using the resultant biases, P and Q\n",
    "        \"\"\"\n",
    "        return mf.b + mf.b_u[:, np.newaxis] + mf.b_i[np.newaxis:,] + mf.P.dot(mf.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 10; error = 0.09607282078386882\n",
      "[[ 4.98632057  3.00079431  3.35652779  1.00834942]\n",
      " [ 3.99098164  2.07780363  3.12441336  1.01347016]\n",
      " [ 0.95429424  1.03175376  3.47626225  4.97060753]\n",
      " [ 1.05347149  1.17222442  2.91033953  4.01960965]\n",
      " [ 2.74647337  1.01132162  4.96684246  4.01664825]]\n"
     ]
    }
   ],
   "source": [
    "R = np.array([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [1, 0, 0, 4],\n",
    "    [0, 1, 5, 4],\n",
    "])\n",
    "\n",
    "mf = MatrixFactorization(R, K=5, alpha=0.1, beta=0.01, iterations=10)\n",
    "res = mf.train()\n",
    "print(mf.full_matrix())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
