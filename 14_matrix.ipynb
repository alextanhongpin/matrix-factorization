{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a490142-3361-4d86-9e18-c6f020ee2ce1",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "https://towardsdatascience.com/recsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5c197-b7ca-4bd4-abf2-0e438f0f2f4a",
   "metadata": {},
   "source": [
    "## 1 - Vanilla Matrix Factorization\n",
    "\n",
    "$R_{ui} = p_u * q_i$\n",
    "\n",
    "Where\n",
    "- $R$ is the rating matrix\n",
    "- subscript $u$ refers to users\n",
    "- subscript $i$ refers to items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd456ea-d783-49fe-99c6-c1a422ae7267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T17:05:01.924233Z",
     "iopub.status.busy": "2024-02-18T17:05:01.914859Z",
     "iopub.status.idle": "2024-02-18T17:05:01.982497Z",
     "shell.execute_reply": "2024-02-18T17:05:01.980992Z",
     "shell.execute_reply.started": "2024-02-18T17:05:01.924157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 0., 1.],\n",
       "       [4., 0., 0., 1.],\n",
       "       [1., 1., 0., 5.],\n",
       "       [1., 0., 0., 4.],\n",
       "       [0., 1., 5., 4.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "R = np.array(\n",
    "    [[5, 3, 0, 1], [4, 0, 0, 1], [1, 1, 0, 5], [1, 0, 0, 4], [0, 1, 5, 4]], dtype=float\n",
    ")\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c07fe8e-ab51-4acf-ac3e-334ffba99f57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T17:11:27.816895Z",
     "iopub.status.busy": "2024-02-18T17:11:27.816183Z",
     "iopub.status.idle": "2024-02-18T17:11:28.302215Z",
     "shell.execute_reply": "2024-02-18T17:11:28.301377Z",
     "shell.execute_reply.started": "2024-02-18T17:11:27.816844Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 10.032804489135742\n",
      "Epoch: 100, Loss: 2.9770305156707764\n",
      "Epoch: 200, Loss: 0.5948803424835205\n",
      "Epoch: 300, Loss: 0.22918803989887238\n",
      "Epoch: 400, Loss: 0.1396285593509674\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        return (self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "\n",
    "\n",
    "def train(model, epochs=10, lr=0.01):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        u, i = R.nonzero()\n",
    "        r = R[R.nonzero()]\n",
    "        users = Variable(torch.LongTensor(u))  # replace df with your dataframe\n",
    "        items = Variable(torch.LongTensor(i))  # replace df with your dataframe\n",
    "        ratings = Variable(torch.FloatTensor(r))  # replace df with your dataframe\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items)\n",
    "        loss = loss_func(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: {}, Loss: {}\".format(epoch, loss.data.item()))\n",
    "\n",
    "\n",
    "n_users, n_items = R.shape\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=3)\n",
    "train(model, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "932b938f-6841-4f8a-89b9-22426106e48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T17:11:29.218310Z",
     "iopub.status.busy": "2024-02-18T17:11:29.217920Z",
     "iopub.status.idle": "2024-02-18T17:11:29.295147Z",
     "shell.execute_reply": "2024-02-18T17:11:29.285784Z",
     "shell.execute_reply.started": "2024-02-18T17:11:29.218280Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.12, 2.48, 3.75, 1.03],\n",
       "       [3.97, 1.5 , 2.32, 0.96],\n",
       "       [1.26, 0.44, 3.54, 4.89],\n",
       "       [0.86, 0.45, 3.1 , 4.06],\n",
       "       [3.74, 1.77, 4.76, 4.09]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users, n_items = R.shape\n",
    "r = np.zeros((n_users, n_items))\n",
    "for i in range(n_users):\n",
    "    for j in range(n_items):\n",
    "        r[i, j] = model(torch.LongTensor([i]), torch.LongTensor([j])).item()\n",
    "np.round(r, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a007543e-c79c-41d1-b98f-30bff0d4e494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T17:11:30.375213Z",
     "iopub.status.busy": "2024-02-18T17:11:30.374829Z",
     "iopub.status.idle": "2024-02-18T17:11:30.385444Z",
     "shell.execute_reply": "2024-02-18T17:11:30.382514Z",
     "shell.execute_reply.started": "2024-02-18T17:11:30.375185Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 0., 1.],\n",
       "       [4., 0., 0., 1.],\n",
       "       [1., 1., 0., 5.],\n",
       "       [1., 0., 0., 4.],\n",
       "       [0., 1., 5., 4.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b2a6a-2cd7-4894-aee0-b724389b4c7a",
   "metadata": {},
   "source": [
    "## 2 - Matrix Factorization with Bias\n",
    "\n",
    "\n",
    "$R_{ui} = p_u * q_i + b + b_i + b_u$\n",
    "\n",
    "Where\n",
    "- $R$ is the rating matrix\n",
    "- subscript $u$ refers to users\n",
    "- subscript $i$ refers to items\n",
    "- $b$ is the average rating\n",
    "- $b_u$ is the user bias\n",
    "- $b_i$ is the item bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67a257fb-0a33-4e6d-9835-8409318eaa83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T17:39:38.276180Z",
     "iopub.status.busy": "2024-02-18T17:39:38.274309Z",
     "iopub.status.idle": "2024-02-18T17:39:38.778999Z",
     "shell.execute_reply": "2024-02-18T17:39:38.778331Z",
     "shell.execute_reply.started": "2024-02-18T17:39:38.276129Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 18.777503967285156\n",
      "Epoch: 100, Loss: 1.3047934770584106\n",
      "Epoch: 200, Loss: 0.2943360507488251\n",
      "Epoch: 300, Loss: 0.12319314479827881\n",
      "Epoch: 400, Loss: 0.06013035029172897\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        self.user_biases = torch.nn.Embedding(n_users, 1)\n",
    "        self.item_biases = torch.nn.Embedding(n_items, 1)\n",
    "        self.global_bias = torch.nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        pred = self.user_biases(user) + self.item_biases(item) + self.global_bias\n",
    "        pred += (self.user_factors(user) * self.item_factors(item)).sum(1, keepdim=True)\n",
    "        return pred.squeeze()\n",
    "\n",
    "\n",
    "def train(model, epochs=10, lr=0.01):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        u, i = R.nonzero()\n",
    "        r = R[R.nonzero()]\n",
    "        users = Variable(torch.LongTensor(u))  # replace df with your dataframe\n",
    "        items = Variable(torch.LongTensor(i))  # replace df with your dataframe\n",
    "        ratings = Variable(torch.FloatTensor(r))  # replace df with your dataframe\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items)\n",
    "        loss = loss_func(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: {}, Loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "\n",
    "n_users, n_items = R.shape\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=3)\n",
    "train(model, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f88fc83-ee6c-4c7a-8637-a6a81ff5695f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T17:39:51.523536Z",
     "iopub.status.busy": "2024-02-18T17:39:51.522207Z",
     "iopub.status.idle": "2024-02-18T17:39:51.562404Z",
     "shell.execute_reply": "2024-02-18T17:39:51.560993Z",
     "shell.execute_reply.started": "2024-02-18T17:39:51.523450Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.11,  2.92,  0.93,  1.22],\n",
       "       [ 3.89,  3.14,  2.38,  0.78],\n",
       "       [ 0.84,  1.12,  3.51,  4.67],\n",
       "       [ 1.15,  3.51,  5.53,  4.26],\n",
       "       [-1.83,  0.93,  5.02,  4.07]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users, n_items = R.shape\n",
    "r = np.zeros((n_users, n_items))\n",
    "for i in range(n_users):\n",
    "    for j in range(n_items):\n",
    "        r[i, j] = model(torch.LongTensor([i]), torch.LongTensor([j])).item()\n",
    "np.round(r, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b7bce25-e5a4-4619-994b-15369d860be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T17:39:59.916354Z",
     "iopub.status.busy": "2024-02-18T17:39:59.915541Z",
     "iopub.status.idle": "2024-02-18T17:39:59.967013Z",
     "shell.execute_reply": "2024-02-18T17:39:59.964798Z",
     "shell.execute_reply.started": "2024-02-18T17:39:59.916302Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 0., 1.],\n",
       "       [4., 0., 0., 1.],\n",
       "       [1., 1., 0., 5.],\n",
       "       [1., 0., 0., 4.],\n",
       "       [0., 1., 5., 4.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55932875-9e76-47e3-8459-b546e4f78078",
   "metadata": {},
   "source": [
    "## 3 — Matrix Factorization with Side Features\n",
    "\n",
    "Incorporating side features into a matrix factorization model can provide additional information that can improve the quality of the recommendations. These side features could be user or item attributes such as user age, user gender, item category, item price, etc.\n",
    "\n",
    "Here's a simple example of how you might modify the above code to include user and item side features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe2b38-4673-4436-9ba3-6a6d26cd12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, n_users, n_items, n_user_features, n_item_features, n_factors=20\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        self.user_biases = torch.nn.Embedding(n_users, 1)\n",
    "        self.item_biases = torch.nn.Embedding(n_items, 1)\n",
    "        self.user_feature_weights = torch.nn.Linear(n_user_features, 1)\n",
    "        self.item_feature_weights = torch.nn.Linear(n_item_features, 1)\n",
    "        self.global_bias = torch.nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, user, item, user_features, item_features):\n",
    "        pred = self.user_biases(user) + self.item_biases(item) + self.global_bias\n",
    "        pred += (self.user_factors(user) * self.item_factors(item)).sum(1, keepdim=True)\n",
    "        pred += (\n",
    "            self.user_feature_weights(user_features).squeeze()\n",
    "            + self.item_feature_weights(item_features).squeeze()\n",
    "        )\n",
    "        return pred.squeeze()\n",
    "\n",
    "\n",
    "def train(model, epochs=10, lr=0.01):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        users = Variable(\n",
    "            torch.LongTensor(df[\"userId\"].values)\n",
    "        )  # replace df with your dataframe\n",
    "        items = Variable(\n",
    "            torch.LongTensor(df[\"movieId\"].values)\n",
    "        )  # replace df with your dataframe\n",
    "        ratings = Variable(\n",
    "            torch.FloatTensor(df[\"rating\"].values)\n",
    "        )  # replace df with your dataframe\n",
    "        user_features = Variable(\n",
    "            torch.FloatTensor(df[\"userFeatures\"].values)\n",
    "        )  # replace df with your dataframe\n",
    "        item_features = Variable(\n",
    "            torch.FloatTensor(df[\"itemFeatures\"].values)\n",
    "        )  # replace df with your dataframe\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items, user_features, item_features)\n",
    "        loss = loss_func(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"Epoch: {}, Loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "\n",
    "n_users = 100  # replace with your actual value\n",
    "n_items = 100  # replace with your actual value\n",
    "n_user_features = 10  # replace with your actual value\n",
    "n_item_features = 10  # replace with your actual value\n",
    "model = MatrixFactorization(n_users, n_items, n_user_features, n_item_features)\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d765c6-888b-472d-9b15-c429df4ec2e5",
   "metadata": {},
   "source": [
    "## 4 — Matrix Factorization with Temporal Features\n",
    "Incorporating temporal features into a matrix factorization model can provide additional information that can improve the quality of the recommendations. These temporal features could be the time of the rating, the user's activity level at different times, seasonal trends, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9e679-d85d-425b-85b1-3f5944819bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_temporal_features, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "        self.user_biases = torch.nn.Embedding(n_users, 1)\n",
    "        self.item_biases = torch.nn.Embedding(n_items, 1)\n",
    "        self.temporal_feature_weights = torch.nn.Linear(n_temporal_features, 1)\n",
    "        self.global_bias = torch.nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, user, item, temporal_features):\n",
    "        pred = self.user_biases(user) + self.item_biases(item) + self.global_bias\n",
    "        pred += (self.user_factors(user) * self.item_factors(item)).sum(1, keepdim=True)\n",
    "        pred += self.temporal_feature_weights(temporal_features).squeeze()\n",
    "        return pred.squeeze()\n",
    "\n",
    "\n",
    "def train(model, epochs=10, lr=0.01):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        users = Variable(\n",
    "            torch.LongTensor(df[\"userId\"].values)\n",
    "        )  # replace df with your dataframe\n",
    "        items = Variable(\n",
    "            torch.LongTensor(df[\"movieId\"].values)\n",
    "        )  # replace df with your dataframe\n",
    "        ratings = Variable(\n",
    "            torch.FloatTensor(df[\"rating\"].values)\n",
    "        )  # replace df with your dataframe\n",
    "        temporal_features = Variable(\n",
    "            torch.FloatTensor(df[\"temporalFeatures\"].values)\n",
    "        )  # replace df with your dataframe\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items, temporal_features)\n",
    "        loss = loss_func(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"Epoch: {}, Loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "\n",
    "n_users = 100  # replace with your actual value\n",
    "n_items = 100  # replace with your actual value\n",
    "n_temporal_features = 10  # replace with your actual value\n",
    "model = MatrixFactorization(n_users, n_items, n_temporal_features)\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0eba44-81f4-4d56-b89d-10b45a3c5026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T17:44:48.143228Z",
     "iopub.status.busy": "2024-02-18T17:44:48.140977Z",
     "iopub.status.idle": "2024-02-18T17:44:48.350695Z",
     "shell.execute_reply": "2024-02-18T17:44:48.342297Z",
     "shell.execute_reply.started": "2024-02-18T17:44:48.143162Z"
    },
    "tags": []
   },
   "source": [
    "## 5 — Factorization Machines\n",
    "Factorization Machines (FMs) are a general-purpose supervised learning algorithm that you can use for both regression and classification tasks. They are a good choice when dealing with high dimensional sparse datasets and can model complex interactions between features using factorized parameters.\n",
    "\n",
    "Here's a simple implementation of Factorization Machines in PyTorch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bfdc6139-0dd3-4b00-b59b-ce93d617a387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T17:53:23.551289Z",
     "iopub.status.busy": "2024-02-18T17:53:23.550868Z",
     "iopub.status.idle": "2024-02-18T17:53:23.706516Z",
     "shell.execute_reply": "2024-02-18T17:53:23.694750Z",
     "shell.execute_reply.started": "2024-02-18T17:53:23.551256Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 55264.94921875\n",
      "Epoch: 1, Loss: 9931461.0\n",
      "Epoch: 2, Loss: 1717193960062976.0\n",
      "Epoch: 3, Loss: inf\n",
      "Epoch: 4, Loss: nan\n",
      "Epoch: 5, Loss: nan\n",
      "Epoch: 6, Loss: nan\n",
      "Epoch: 7, Loss: nan\n",
      "Epoch: 8, Loss: nan\n",
      "Epoch: 9, Loss: nan\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class FactorizationMachine(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_factors):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_factors = n_factors\n",
    "        self.linear = torch.nn.Linear(n_features, 1)\n",
    "        self.v = torch.nn.Parameter(torch.randn(n_features, n_factors))\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear_part = self.linear(x)\n",
    "        t0 = (x @ self.v) ** 2\n",
    "        t1 = (x ** 2) @ (self.v ** 2)\n",
    "        factor_part = 0.5 * (t0 - t1).sum(1, keepdim=True)\n",
    "        return linear_part + factor_part\n",
    "\n",
    "\n",
    "def train(model, data, target, epochs=10, lr=0.01):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(data)\n",
    "        loss = loss_func(predictions, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"Epoch: {}, Loss: {}\".format(epoch, loss.item()))\n",
    "\n",
    "\n",
    "n_features = 100  # replace with your actual value\n",
    "n_factors = 10  # replace with your actual value\n",
    "model = FactorizationMachine(n_features, n_factors)\n",
    "\n",
    "# replace data and target with your actual data\n",
    "data = torch.randn(1000, n_features)\n",
    "target = torch.randn(1000, 1)\n",
    "train(model, data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f4f6d-79f6-495e-b925-8db9ad031e10",
   "metadata": {},
   "source": [
    "## Setting data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6240c7ac-3670-441d-911a-bb8cd876508b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T18:03:17.621997Z",
     "iopub.status.busy": "2024-02-18T18:03:17.621682Z",
     "iopub.status.idle": "2024-02-18T18:03:17.643837Z",
     "shell.execute_reply": "2024-02-18T18:03:17.642882Z",
     "shell.execute_reply.started": "2024-02-18T18:03:17.621975Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': tensor([2]), 'item': tensor([1]), 'rating': tensor([1.])}\n",
      "{'user': tensor([0]), 'item': tensor([1]), 'rating': tensor([3.])}\n",
      "{'user': tensor([4]), 'item': tensor([1]), 'rating': tensor([1.])}\n",
      "{'user': tensor([4]), 'item': tensor([3]), 'rating': tensor([4.])}\n",
      "{'user': tensor([3]), 'item': tensor([0]), 'rating': tensor([1.])}\n",
      "{'user': tensor([4]), 'item': tensor([2]), 'rating': tensor([5.])}\n",
      "{'user': tensor([1]), 'item': tensor([3]), 'rating': tensor([1.])}\n",
      "{'user': tensor([3]), 'item': tensor([3]), 'rating': tensor([4.])}\n",
      "{'user': tensor([0]), 'item': tensor([3]), 'rating': tensor([1.])}\n",
      "{'user': tensor([2]), 'item': tensor([0]), 'rating': tensor([1.])}\n",
      "{'user': tensor([1]), 'item': tensor([0]), 'rating': tensor([4.])}\n",
      "{'user': tensor([2]), 'item': tensor([3]), 'rating': tensor([5.])}\n",
      "{'user': tensor([0]), 'item': tensor([0]), 'rating': tensor([5.])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, users, items, ratings):\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.ratings = ratings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"user\": torch.tensor(self.users[idx], dtype=torch.long),\n",
    "            \"item\": torch.tensor(self.items[idx], dtype=torch.long),\n",
    "            \"rating\": torch.tensor(self.ratings[idx], dtype=torch.float),\n",
    "        }\n",
    "\n",
    "\n",
    "# replace with your actual data\n",
    "users, items = R.nonzero()\n",
    "ratings = R[R.nonzero()]\n",
    "\n",
    "dataset = MovieDataset(users, items, ratings)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for batch in data_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec3401-cb83-43d0-956d-2fdfdffb765e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
